<!doctype html><html lang=en><head><meta charset=utf-8><title>Beyond Round Robin: Load Balancing for Latency | Linkerd</title>
<link rel="shortcut icon" href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This post was co-written with Ruben Oanta (@rubeydoo).
Load balancing is a critical component of any large-scale software deployment. But there are many ways to do load balancing. Which way is best? And how can we evaluate the different options?
In the modern software ecosystem, load balancing plays several roles. First, it is fundamental to the notion of scalability. Software is deployed in multiple, identical replicas. We “scale” software by deploying additional replicas. Traffic must be distributed across replicas, and this distribution is the act of load balancing."><meta property="og:url" content="https://travisbeckham.github.io/2016/03/16/beyond-round-robin-load-balancing-for-latency/"><meta property="og:site_name" content="Linkerd"><meta property="og:title" content="Beyond Round Robin: Load Balancing for Latency"><meta property="og:description" content="This post was co-written with Ruben Oanta (@rubeydoo).
Load balancing is a critical component of any large-scale software deployment. But there are many ways to do load balancing. Which way is best? And how can we evaluate the different options?
In the modern software ecosystem, load balancing plays several roles. First, it is fundamental to the notion of scalability. Software is deployed in multiple, identical replicas. We “scale” software by deploying additional replicas. Traffic must be distributed across replicas, and this distribution is the act of load balancing."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2016-03-16T00:00:00+00:00"><meta property="article:modified_time" content="2016-03-16T00:00:00+00:00"><meta property="og:image" content="https://travisbeckham.github.io/2016/03/16/beyond-round-robin-load-balancing-for-latency/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://travisbeckham.github.io/2016/03/16/beyond-round-robin-load-balancing-for-latency/cover.png"><meta name=twitter:title content="Beyond Round Robin: Load Balancing for Latency"><meta name=twitter:description content="This post was co-written with Ruben Oanta (@rubeydoo).
Load balancing is a critical component of any large-scale software deployment. But there are many ways to do load balancing. Which way is best? And how can we evaluate the different options?
In the modern software ecosystem, load balancing plays several roles. First, it is fundamental to the notion of scalability. Software is deployed in multiple, identical replicas. We “scale” software by deploying additional replicas. Traffic must be distributed across replicas, and this distribution is the act of load balancing."><meta name=twitter:site content="@Linkerd"><link rel=canonical href=https://travisbeckham.github.io/2016/03/16/beyond-round-robin-load-balancing-for-latency/><link rel=stylesheet href=/css/main.css><script src=/js/main.js></script><script async defer src=https://buttons.github.io/buttons.js></script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","author":"Steve Jenson","datePublished":"2016-03-16T00:00:00Z","dateModified":"2016-03-16T00:00:00Z","headline":"Beyond Round Robin: Load Balancing for Latency","image":"https://travisbeckham.github.io/2016/03/16/beyond-round-robin-load-balancing-for-latency/cover.png","publisher":{"@type":"Organization","name":"linkerd.io","logo":{"@type":"ImageObject","url":"https://travisbeckham.github.io/logos/linkerd.png","width":472,"height":100}}}</script></head><body><header class=main-header><div class=main-header__container><div class=main-header__logo><a href=/><img src=/logos/linkerd.png alt=Linkerd></a></div><input class=main-header__toggle-checkbox type=checkbox id=main-header-toggle>
<label class=main-header__toggle for=main-header-toggle><span class=main-header__toggle-icon><span class=main-header__toggle-icon--open><svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M3 6H21V8H3V6m0 5H21v2H3V11m0 5H21v2H3V16z"/></svg>
</span><span class=main-header__toggle-icon--close><svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg></span></span></label><div class=main-header__nav><nav class=main-nav><ul class=main-nav__menu><li><a href=/docs>Docs</a></li><li><a href=#>Community<svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M7.41 8.58 12 13.17l4.59-4.59L18 10l-6 6-6-6L7.41 8.58z"/></svg></a><ul><li><a href=/community/get-involved/>Get Involved</a></li><li><a href=/community/adopters/>Adopters</a></li><li><a href=/community/ambassadors/>Linkerd Ambassadors</a></li><li><a href=https://linkerd.buoyant.io target=_blank rel=noopener>Buoyant's Linkerd Forum</a></li></ul></li><li class=main-nav__menu--selected><a href=/blog/>Blog</a></li><li><a href=/faq/>FAQ</a></li><li><a href=/enterprise/>Enterprise</a></li></ul><div class=main-nav__search><form action=/search method=get><div class="search-input search-input--sm"><svg class="icon" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5.0 0116 9.5c0 1.61-.59 3.09-1.56 4.23L14.71 14H15.5l5 5L19 20.5l-5-5V14.71L13.73 14.44C12.59 15.41 11.11 16 9.5 16A6.5 6.5.0 013 9.5 6.5 6.5.0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
<input type=text name=q placeholder=Search></div></form></div><div class=main-nav__github><a class=github-button href=https://github.com/linkerd/linkerd2 data-icon=octicon-star data-size=large data-show-count=true aria-label="Star linkerd/linkerd2 on GitHub">Star</a></div><div class=main-nav__forum><a href=https://linkerd.buoyant.io class="button button--primary button--sm" target=_blank rel=noopener>Join Forum</a></div></nav></div></div></header><div class=main-announcement>Service Mesh 101: Get Service Mesh-Certified
<span class=main-announcement__link><a href=https://buoyant.io/courses/service-mesh-101 target=_blank rel=noopener>Enroll now</a></span></div><main class=main-content><div class="blog blog--single"><div class="blog__container container"><div class=blog-post><div class=blog-post__header><h1>Beyond Round Robin: Load Balancing for Latency</h1><div class=blog-post-meta><div class=blog-post-meta__media><img src=/authors/steve-jenson.jpg alt="Steve Jenson" class="img img--48 img--round"></div><div class=blog-post-meta__body><div class=blog-post-meta__name>Steve Jenson</div><div class=blog-post-meta__date>Mar 16, 2016 • 6 min read</div></div></div></div><div class=blog-post__cover></div><div class="blog-post__content prose"><p>This post was co-written with Ruben Oanta (@rubeydoo).</p><p>Load balancing is a critical component of any large-scale software deployment. But there are many ways to do load balancing. Which way is best? And how can we evaluate the different options?</p><p>In the modern software ecosystem, load balancing plays several roles. First, it is fundamental to the notion of <em>scalability</em>. Software is deployed in multiple, identical replicas. We “scale” software by deploying additional replicas. Traffic must be distributed across replicas, and this distribution is the act of load balancing.</p><p>Load balancing provides another necessary feature: that of <em>resilience</em>. Intuitively speaking, a resilient system is one in which the failure of individual components does not cause the system itself to fail. Software, or the hardware on which it runs, will fail. By distributing traffic only to instances which are capable of serving it, load balancing allows us to join multiple fallible components into a single resilient system.</p><p>We can extend this model of resilience one step further, to address another unwelcome visitor in distributed systems: <em>latency</em>. Just as the components of a system may fail, so too may they become slow. A good load balancer must protect against latency, just as it protects against failure. Even in the presence of slow replicas, the system as a whole must remain fast.</p><p>This third criterion is more subtle than the first two. Algorithmically speaking, addressing scalability and resilience is straightforward: given a set of replicas, distribute traffic across all live replicas, and don’t distribute traffic to replicas that have failed. (We will ignore, for the moment, the not insignificant challenge of assessing the health of a replica.) For latency, the story is less clear: given a set of replicas performing at a variety of speeds, what is the best strategy for distributing load among them?</p><p>In this article, we run a simple experiment with three algorithms: round robin, least loaded, and peak exponentially-weighted moving average (“peak EWMA”). The three algorithms serve as a test bed for demonstrating the effect that the right—or wrong—choice of load balancing algorithm can have. In particular, we test the effectiveness of these algorithms at handling component latency.</p><p>Loosely speaking, the three algorithms behave as follows:</p><ul><li><strong>Round robin</strong>: distribute requests to each replica in turn.</li><li><strong>Least loaded</strong>: maintain a count of outstanding requests to each replica, and distribute traffic to replicas with the smallest number of outstanding requests.</li><li><strong>Peak EWMA</strong>: maintain a moving average of each replica’s round-trip time, weighted by the number of outstanding requests, and distribute traffic to replicas where that cost function is smallest.</li></ul><p>Of these three algorithms, round robin is commonly seen in practice, and is available in most software load balancers, including Nginx and HAProxy. The other two algorithms are less common in the wild, but production-tested implementations of both are available in <a href=https://finagle.github.io/ target=_blank rel=noopener>Finagle</a>, Twitter’s client-side RPC library.</p><h2 id=experiment-setup>Experiment setup</h2><p>We ran a simple simulation to measure the effect of component latency on overall system latency, using the following scenario:</p><ul><li>11 backend servers, each replaying latency captured from a production system. This latency distribution has a median of 167ms, a standard deviation of 5ms, and no significant peaks.</li><li>One client, running at 1000 qps, balancing across all 11 backends.</li><li>One minute total run.</li><li>After 15 seconds, a single server’s latency was fixed to 2 seconds for 30 seconds, then returned to normal. (This simulates a backend service suffering from a bad garbage collection pause, or other transient issue.)</li></ul><p>We used a basic RPC client written with Finagle for these experiments.</p><p>(Note that Finagle does not include a round robin implementation by default. In order to reduce variance across experimental conditions, we added an implementation for this experiment. You can download the code used in this experiment <a href=https://github.com/BuoyantIO/finagle/blob/stevej/simulate_rr/finagle-benchmark/src/main/scala/com/twitter/finagle/loadbalancer/Simulation.scala target=_blank rel=noopener>here</a>.)</p><h2 id=results>Results</h2><figure><img alt=results class="img img--max-fill img--center img--rounded" src=/2016/03/16/beyond-round-robin-load-balancing-for-latency/buoyant-latency-experiment-results.png></figure><p>The results of the experiment are shown in the graph above. The y axis denotes latency, and the x axis (log scale) denotes the percentile in the latency distribution at which that latency was exceeded.</p><p>The difference in performance between the three algorithms in the face of a slow server is clear. Round robin suffers the most, exhibiting slow performance above the 95th percentile. Least loaded fared better, maintaining fast performance until the 99th percentile, and peak EWMA fares even better, maintaining speed until the 99.9th percentile.</p><p>Since latency and failure are often tied together in distributed systems via timeouts, we can also express the results in terms of failure. If the caller of our system used a timeout of 1 second, its success rate would be approximately 95% with round robin, 99% with least loaded, and 99.9% with peak EWMA—a significant difference.</p><h2 id=discussion>Discussion</h2><p>Round robin is clearly the worst performer of the three algorithms examined. In some respects, this is unsurprising: it is also the most naive.</p><p>However, round robin is not just a worse algorithm—it does not take advantage of the information available to least loaded and peak EWMA. Because Finagle operates at Layer 5 in the OSI model (the “session” layer), it has access to information such as queue depth and RPC latencies. Least loaded takes advantage of queue depth and shows significantly improved performance above round robin; peak EWMA takes into account both RPC latency and queue depth and shows even better performance. The difference between the three options is not so much an algorithmic one as a difference in the information used to make balancing decisions.</p><p>Of course, in practice, there are many factors that affect load balancing performance beyond choice of algorithm. The implementation may have poor performance under high concurrency. The algorithm may be unsuitable for certain classes of requests, such as long polling requests (in which case high latency is expected, and not a symptom of failure). The algorithm may be unsuitable for particular client/server relationships, such as highly asymmetric replica counts. In this article, we have not attempted to present a comprehensive analysis, and have expended only a minimum amount of effort to control for these variables. Our intention is simply to provide an example of the difference that algorithmic choice can make.</p><p>That said, large-scale production experiments at Twitter have verified the effectiveness of least loaded and peak EWMA (as well as other load balancing algorithms), and these algorithms are used at scale to power much of Twitter’s infrastructure today.</p><h2 id=conclusion>Conclusion</h2><p>For systems that load balance higher-level connections such as RPC or HTTP calls, where Layer 5 information such as endpoint latencies and request depths are available, round robin load balancing can perform significantly worse than other algorithms in the presence of slow endpoints. These systems may show significantly improved performance in the face of slow endpoints by using algorithms that can take advantage of Layer 5 information.</p><p>If the results above are applicable to your situation, you may want to take advantage of algorithms like least loaded and peak EWMA. Production-tested implementations of these algorithms are available today in <a href=https://finagle.github.io/ target=_blank rel=noopener>Finagle</a>, and in <a href=https://linkerd.io/ target=_blank rel=noopener>Linkerd</a>, the open-source service mesh for cloud-native applications. (See <a href=https://api.linkerd.io/latest/linkerd/index.html target=_blank rel=noopener>here</a> for how to configure the load balancing algorithms in Linkerd.)</p><h2 id=acknowledgments>Acknowledgments</h2><p>Thanks to <a href=https://twitter.com/marius target=_blank rel=noopener>Marius Eriksen</a>, <a href=https://twitter.com/adlleong target=_blank rel=noopener>Alex Leong</a>, <a href=https://twitter.com/klingerf target=_blank rel=noopener>Kevin Lingerfelt</a>, and <a href=https://twitter.com/wm target=_blank rel=noopener>William Morgan</a> for feedback on early drafts of this document.</p><h2 id=further-reading>Further reading</h2><ul><li>The Tail at Scale. <a href=http://cacm.acm.org/magazines/2013/2.16/160173-the-tail-at-scale/abstract target=_blank rel=noopener>http://cacm.acm.org/magazines/2013/2.16/160173-the-tail-at-scale/abstract</a></li><li>Michael Mitzenmacher. 2001. <em>The Power of Two Choices in Randomized Load Balancing</em>. IEEE Trans. Parallel Distrib. Syst. 12, 10 (October 2001), 1094-1104.</li></ul></div></div><div class=blog-post-related><h2>Suggested Blog Posts</h2><div class=blog-post-related__pages><div class="card card--horz card--center"><div class=card__media><img src=/2019/02/12/announcing-linkerd-2.2/cover.png alt=Cover class="img img--128 img--rounded"></div><div class=card__body><div class=card__header><h4><a href=/2019/02/12/announcing-linkerd-2.2/>Announcing Linkerd 2.2</a></h4><div class=blog-post-meta><div class=blog-post-meta__date>Feb 12, 2019 • 5 min read</div></div></div></div></div><div class="card card--horz card--center"><div class=card__media><img src=/2018/10/19/the-linkerd-enthusiasts-guide-to-kubecon-na-2018-2/cover.png alt=Cover class="img img--128 img--rounded"></div><div class=card__body><div class=card__header><h4><a href=/2018/10/19/the-linkerd-enthusiasts-guide-to-kubecon-na-2018-2/>The Linkerd Enthusiast’s Guide to Kubecon NA 2018</a></h4><div class=blog-post-meta><div class=blog-post-meta__date>Oct 19, 2018 • 2 min read</div></div></div></div></div><div class="card card--horz card--center"><div class=card__media><img src=/2024/10/15/linkerd-edge-release-roundup/thumbnail.png alt=Thumbnail class="img img--128 img--rounded"></div><div class=card__body><div class=card__header><h4><a href=/2024/10/15/linkerd-edge-release-roundup/>Linkerd Edge Release Roundup: October 2024</a></h4><div class=blog-post-meta><div class=blog-post-meta__date>Oct 15, 2024 • 4 min read</div></div></div></div></div></div></div></div></div></main><footer class=main-footer><div class=main-footer__top><div class="main-footer__container container"><div class=main-footer__info><p><img src=/logos/linkerd.png alt=Linkerd></p><p>Linkerd was originally created by <a href=https://buoyant.io/ target=_blank rel=noopener>Buoyant</a></p><p>View <a href=https://github.com/linkerd/linkerd/wiki/Linkerd-code-of-conduct target=_blank rel=noopener>Code of Conduct</a></p></div><div class=main-footer__links><div class=main-footer__community><h4>Community</h4><ul><li><a href=https://github.com/linkerd/linkerd2 target=_blank rel=noopener>GitHub</a></li><li><a href=https://slack.linkerd.io target=_blank rel=noopener>Slack</a></li><li><a href=https://linkerd.buoyant.io target=_blank rel=noopener>Linkerd Forum</a></li></ul></div><div class=main-footer__follow><h4>Follow</h4><ul><li><a href=https://www.linkedin.com/company/linkerd/ target=_blank rel=noopener>Linkedin</a></li><li><a href=https://www.youtube.com/buoyantio target=_blank rel=noopener>YouTube</a></li><li><a href=https://twitter.com/linkerd target=_blank rel=noopener>Twitter</a></li></ul></div></div></div></div><div class=main-footer__bottom><div class="main-footer__container container"><p><a href=https://github.com/linkerd/website/tree/main/linkerd.io/content target=_blank rel=noopener>Edit This Site</a></p><p>Copyright © 2024 Linkerd Authors. All rights reserved.</p></div></div></footer></body></html>