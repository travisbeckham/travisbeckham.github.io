<!doctype html><html lang=en><head><meta charset=utf-8><title>Slow Cooker: Load testing for tough software | Linkerd</title>
<link rel="shortcut icon" href=/favicon.png><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Linkerd, our service mesh for cloud-native applications, needs to handle very high volumes of production traffic over extended periods of time. In this post, we’ll describe the load testing strategies and tools we use to ensure Linkerd can meet this goal. We’ll review some of the problems we faced when trying to use popular load testers. Finally, we’ll introduce slow_cooker, an open source load tester written in Go, which is designed for long-running load tests and lifecycle issue identification."><meta property="og:url" content="https://travisbeckham.github.io/2016/12/10/slow-cooker-load-testing-for-tough-software/"><meta property="og:site_name" content="Linkerd"><meta property="og:title" content="Slow Cooker: Load testing for tough software"><meta property="og:description" content="Linkerd, our service mesh for cloud-native applications, needs to handle very high volumes of production traffic over extended periods of time. In this post, we’ll describe the load testing strategies and tools we use to ensure Linkerd can meet this goal. We’ll review some of the problems we faced when trying to use popular load testers. Finally, we’ll introduce slow_cooker, an open source load tester written in Go, which is designed for long-running load tests and lifecycle issue identification."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2016-12-10T00:00:00+00:00"><meta property="article:modified_time" content="2016-12-10T00:00:00+00:00"><meta property="og:image" content="https://travisbeckham.github.io/2016/12/10/slow-cooker-load-testing-for-tough-software/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://travisbeckham.github.io/2016/12/10/slow-cooker-load-testing-for-tough-software/cover.png"><meta name=twitter:title content="Slow Cooker: Load testing for tough software"><meta name=twitter:description content="Linkerd, our service mesh for cloud-native applications, needs to handle very high volumes of production traffic over extended periods of time. In this post, we’ll describe the load testing strategies and tools we use to ensure Linkerd can meet this goal. We’ll review some of the problems we faced when trying to use popular load testers. Finally, we’ll introduce slow_cooker, an open source load tester written in Go, which is designed for long-running load tests and lifecycle issue identification."><meta name=twitter:site content="@Linkerd"><link rel=canonical href=https://travisbeckham.github.io/2016/12/10/slow-cooker-load-testing-for-tough-software/><link rel=stylesheet href=/css/main.css><script src=/js/main.js></script><script async defer src=https://buttons.github.io/buttons.js></script><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","author":"Steve Jenson","datePublished":"2016-12-10T00:00:00Z","dateModified":"2016-12-10T00:00:00Z","headline":"Slow Cooker: Load testing for tough software","image":"https://travisbeckham.github.io/2016/12/10/slow-cooker-load-testing-for-tough-software/cover.png","publisher":{"@type":"Organization","name":"linkerd.io","logo":{"@type":"ImageObject","url":"https://travisbeckham.github.io/logos/linkerd.png","width":472,"height":100}}}</script></head><body><header class=main-header><div class=main-header__container><div class=main-header__logo><a href=/><img src=/logos/linkerd.png alt=Linkerd></a></div><input class=main-header__toggle-checkbox type=checkbox id=main-header-toggle>
<label class=main-header__toggle for=main-header-toggle><span class=main-header__toggle-icon><span class=main-header__toggle-icon--open><svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M3 6H21V8H3V6m0 5H21v2H3V11m0 5H21v2H3V16z"/></svg>
</span><span class=main-header__toggle-icon--close><svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg></span></span></label><div class=main-header__nav><nav class=main-nav><ul class=main-nav__menu><li><a href=/docs>Docs</a></li><li><a href=#>Community<svg class="icon icon--primary" viewBox="0 0 24 24"><path d="M7.41 8.58 12 13.17l4.59-4.59L18 10l-6 6-6-6L7.41 8.58z"/></svg></a><ul><li><a href=/community/get-involved/>Get Involved</a></li><li><a href=/community/adopters/>Adopters</a></li><li><a href=/community/ambassadors/>Linkerd Ambassadors</a></li><li><a href=https://linkerd.buoyant.io target=_blank rel=noopener>Buoyant's Linkerd Forum</a></li></ul></li><li class=main-nav__menu--selected><a href=/blog/>Blog</a></li><li><a href=/faq/>FAQ</a></li><li><a href=/enterprise/>Enterprise</a></li></ul><div class=main-nav__search><form action=/search method=get><div class="search-input search-input--sm"><svg class="icon" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5.0 0116 9.5c0 1.61-.59 3.09-1.56 4.23L14.71 14H15.5l5 5L19 20.5l-5-5V14.71L13.73 14.44C12.59 15.41 11.11 16 9.5 16A6.5 6.5.0 013 9.5 6.5 6.5.0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
<input type=text name=q placeholder=Search></div></form></div><div class=main-nav__github><a class=github-button href=https://github.com/linkerd/linkerd2 data-icon=octicon-star data-size=large data-show-count=true aria-label="Star linkerd/linkerd2 on GitHub">Star</a></div><div class=main-nav__forum><a href=https://linkerd.buoyant.io class="button button--primary button--sm" target=_blank rel=noopener>Join Forum</a></div></nav></div></div></header><div class=main-announcement><strong>Oct 23, 2024</strong> New blog post: Towards a Sustainable Service Mesh.
<a href=/2024/10/23/making-linkerd-sustainable/ class=main-announcement__link>Read the post</a></div><main class=main-content><div class="blog blog--single"><div class="blog__container container"><div class=blog-post><div class=blog-post__header><h1>Slow Cooker: Load testing for tough software</h1><div class=blog-post-meta><div class=blog-post-meta__media><img src=/authors/steve-jenson_hu1272952644139488557.jpg alt="Steve Jenson" class="img img--48 img--round"></div><div class=blog-post-meta__body><div class=blog-post-meta__name>Steve Jenson</div><div class=blog-post-meta__date>Dec 10, 2016 • 10 min read</div></div></div></div><div class=blog-post__cover></div><div class="blog-post__content prose"><p>Linkerd, our service mesh for cloud-native applications, needs to handle very high volumes of production traffic over extended periods of time. In this post, we’ll describe the load testing strategies and tools we use to ensure Linkerd can meet this goal. We’ll review some of the problems we faced when trying to use popular load testers. Finally, we’ll introduce <strong>slow_cooker</strong>, an open source load tester written in Go, which is designed for long-running load tests and lifecycle issue identification.</p><p>As a service mesh, <a href=http://linkerd.io/ target=_blank rel=noopener>Linkerd</a> acts as a transparent proxy, taking requests destined for a particular service and adding connection pooling, failure handling, retries, latency-aware load balancing, and more. In order to be a viable production system, Linkerd needs to handle very high request loads over long periods of time and a variety of conditions. Happily, Linkerd is built on top of <a href=http://netty.io/ target=_blank rel=noopener>netty</a> and <a href=https://twitter.github.io/finagle/ target=_blank rel=noopener>Finagle</a>, some of the most widely tested and production-vetted network code known to man. But code is one thing; performance in the real world is another.</p><p>To assess production behavior, Linkerd needs to be vetted by extensive and rigorous load testing. Furthremore, since Linkerd is a part of underlying infrastructure, Linkerd instances are rarely stopped or restarted—a single Linkerd instance may see billions of requests over a variety of client and service behaviors. This means we must also test for <em>lifecycle issues</em>. For high-throughput network servers like Linkerd, lifecycle issues include memory leaks, socket leaks, bad GC pauses, and periodic network or disk saturation. While these things happen infrequently, if they aren’t handled properly, the results can be catastrophic.</p><h2 id=who-tests-the-testers>Who tests the testers?</h2><p>Early on in Linkerd development, we used popular load testers like <a href=http://httpd.apache.org/docs/2.4/programs/ab.html target=_blank rel=noopener>ApacheBench</a> and <a href=https://github.com/rakyll/hey target=_blank rel=noopener>hey</a>. (Of course, these are HTTP-specific, and Linkerd proxies a variety of protocols, including Thrift, gRPC, and Mux—but we needed to start somewhere.)</p><p>Unfortunately, we quickly found that while these tools were great for getting a quick read on performance, they weren’t great for identifying the lifecycle issues we wanted to capture. These tools would provide a single end-of-run summary, which could mask real issues. They also relied on means and standard deviations, which we knew was a problematic way to characterize system performance.</p><p>For capturing lifecycle issues, we wanted both better metrics and to the ability to see how Linkerd was performing over long tests runs of hours or days rather than minutes.</p><h2 id=slow-cooking-for-tender-code>Slow cooking for tender code</h2><p>Since we couldn’t find a tool that did what we needed, we built one: <a href=https://github.com/buoyantio/slow_cooker target=_blank rel=noopener>slow_cooker</a>. slow_cooker is a load tester designed explicitly for long-running load tests to identify lifecycle issues. We use slow_cooker extensively to find performance issues and test changes in our products. It features incremental progress reports, change detection, and comprehensive metrics.</p><p>Today, we’re open sourcing slow_cooker for others to use and contribute to. You can check out the <a href=https://github.com/buoyantio/slow_cooker target=_blank rel=noopener>source on GitHub</a> or try out the <a href=https://github.com/buoyantio/slow_cooker/releases target=_blank rel=noopener>recently released 1.0 version</a>.</p><p>Let’s take a look at some of slow_cooker’s features.</p><p>(For the sake of simplicity, we’ll show the output of slow_cooker when we change performance characteristics of the downstream services. In practice, of course, we use slow_cooker primarily to identify problems with Linkerd, not the services it’s talking to.)</p><h2 id=incremental-latency-reports>Incremental latency reports</h2><p>slow_cooker has an incremental reporting approach, motivated by our focus on finding lifecycle issues over a long period of time. Too much can get lost when looking at an aggregate report over a very large amount of data—especially for transient issues like GC pressure or network saturation. With incremental reports, we can see throughput and latency trends or changes in a running system.</p><p>In the example below, we show slow_cooker output from load testing Linkerd. Our test scenario has Linkerd load balancing across 3 nginx backends, each serving static content. The latencies given are in milliseconds, and we report the min, p50, p95, p99, p999, and max latencies seen during this 10 second interval.</p><div class=highlight><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>$ ./slow_cooker_linux_amd64 -url http://target:4140 -qps 50 -concurrency 10 http://perf-target-2:8080
</span></span><span style=display:flex><span>    # sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ...
</span></span><span style=display:flex><span>    #                      good/b/f t     good%   min [p50 p95 p99  p999]  max change
</span></span><span style=display:flex><span>    2016-10-12T20:34:20Z   4990/0/0 5000  99% 10s   0 [  1   3   4    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:34:30Z   5020/0/0 5000 100% 10s   0 [  1   3   6   11 ]   11
</span></span><span style=display:flex><span>    2016-10-12T20:34:40Z   5020/0/0 5000 100% 10s   0 [  1   3   7   10 ]   10
</span></span><span style=display:flex><span>    2016-10-12T20:34:50Z   5020/0/0 5000 100% 10s   0 [  1   3   5    8 ]    8
</span></span><span style=display:flex><span>    2016-10-12T20:35:00Z   5020/0/0 5000 100% 10s   0 [  1   3   5    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:35:11Z   5020/0/0 5000 100% 10s   0 [  1   3   5   11 ]   11
</span></span><span style=display:flex><span>    2016-10-12T20:35:21Z   5020/0/0 5000 100% 10s   0 [  1   3   5    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:36:11Z   5020/0/0 5000 100% 10s   0 [  1   3   5    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:36:21Z   5020/0/0 5000 100% 10s   0 [  1   3   6    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:35:31Z   5019/0/0 5000 100% 10s   0 [  1   3   5    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:35:41Z   5020/0/0 5000 100% 10s   0 [  1   3   6   10 ]   10
</span></span><span style=display:flex><span>    2016-10-12T20:35:51Z   5020/0/0 5000 100% 10s   0 [  1   3   5    9 ]    9
</span></span><span style=display:flex><span>    2016-10-12T20:36:01Z   5020/0/0 5000 100% 10s   0 [  1   3   5   10 ]   10
</span></span></code></pre></div><p>In this report, <code>good%</code> measures throughput: how close we’re getting to the requested RPS (requests per second).</p><p>This report looks good—the system is fast and response times are stable. When things go bad, however, we need that fact to come across clearly. We designed slow_cooker’s output to make it easy to visually scan for issues and outliers by using vertical alignment and a change indicator helps us to spot outliers in latency. In the example below, we have a backend server suffering from a catastrophic slow down:</p><div class=highlight><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>$ ./slow_cooker_linux_amd64 -totalRequests 100000 -qps 5 -concurrency 100 http://perf-target-1:8080
</span></span><span style=display:flex><span>    # sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ...
</span></span><span style=display:flex><span>    #                      good/b/f t     good%   min [p50 p95 p99  p999]  max change
</span></span><span style=display:flex><span>    2016-11-14T20:58:13Z   4900/0/0 5000  98% 10s   0 [  1   2   6    8 ]    8 +
</span></span><span style=display:flex><span>    2016-11-14T20:58:23Z   5026/0/0 5000 100% 10s   0 [  1   2   3    4 ]    4
</span></span><span style=display:flex><span>    2016-11-14T20:58:33Z   5017/0/0 5000 100% 10s   0 [  1   2   3    4 ]    4
</span></span><span style=display:flex><span>    2016-11-14T20:58:43Z   1709/0/0 5000  34% 10s   0 [  1 6987 6987 6987 ] 6985 +++
</span></span><span style=display:flex><span>    2016-11-14T20:58:53Z   5020/0/0 5000 100% 10s   0 [  1   2   2    3 ]    3 --
</span></span><span style=display:flex><span>    2016-11-14T20:59:03Z   5018/0/0 5000 100% 10s   0 [  1   2   2    3 ]    3 --
</span></span><span style=display:flex><span>    2016-11-14T20:59:13Z   5010/0/0 5000 100% 10s   0 [  1   2   2    3 ]    3 --
</span></span><span style=display:flex><span>    2016-11-14T20:59:23Z   4985/0/0 5000  99% 10s   0 [  1   2   2    3 ]    3 --
</span></span><span style=display:flex><span>    2016-11-14T20:59:33Z   5015/0/0 5000 100% 10s   0 [  1   2   3    4 ]    4 --
</span></span><span style=display:flex><span>    2016-11-14T20:59:43Z   5000/0/0 5000 100% 10s   0 [  1   2   3    5 ]    5
</span></span><span style=display:flex><span>    2016-11-14T20:59:53Z   5000/0/0 5000 100% 10s   0 [  1   2   2    3 ]    3
</span></span><span style=display:flex><span>    FROM    TO #REQUESTS
</span></span><span style=display:flex><span>       0     2 49159
</span></span><span style=display:flex><span>       2     8 4433
</span></span><span style=display:flex><span>       8    32 8
</span></span><span style=display:flex><span>      32    64 0
</span></span><span style=display:flex><span>      64   128 0
</span></span><span style=display:flex><span>     128   256 0
</span></span><span style=display:flex><span>     256   512 0
</span></span><span style=display:flex><span>     512  1024 0
</span></span><span style=display:flex><span>    1024  4096 0
</span></span><span style=display:flex><span>    4096 16384 100
</span></span></code></pre></div><p>As you can see, the system is fast and responsive except for a hiccup at 2016-11-14T20:58:43Z. During this hiccup, our throughput dropped to 34% and then returned to normal. As a service owner, you’d want to look into your logs or performance metrics and investigate the root cause.</p><h2 id=lifecycle-issue-example-gc-pause>Lifecycle issue example: GC pause</h2><p>In order to demonstrate how incremental reporting can provide benefits over a single final report, let’s do a simulation of a backend service having GC trouble. In this example, we’ll test directly against a single nginx process serving static content, and in a loop we’ll continually pause and then unpause the process at 5 second intervals (using <code>kill -STOP $PID</code> and <code>kill -CONT $pid</code>).</p><p>For comparison, let’s start with a <a href=http://httpd.apache.org/docs/2.4/programs/ab.html target=_blank rel=noopener>ApacheBench</a>’s report:</p><div class=highlight><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>$ ab -n 100000 -c 10 http://perf-target-1:8080/
</span></span><span style=display:flex><span>    This is ApacheBench, Version 2.3
</span></span><span style=display:flex><span>    Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
</span></span><span style=display:flex><span>    Licensed to The Apache Software Foundation, http://www.apache.org/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Benchmarking perf-target-1 (be patient)
</span></span><span style=display:flex><span>    Completed 10000 requests
</span></span><span style=display:flex><span>    Completed 20000 requests
</span></span><span style=display:flex><span>    Completed 30000 requests
</span></span><span style=display:flex><span>    Completed 40000 requests
</span></span><span style=display:flex><span>    Completed 50000 requests
</span></span><span style=display:flex><span>    Completed 60000 requests
</span></span><span style=display:flex><span>    Completed 70000 requests
</span></span><span style=display:flex><span>    Completed 80000 requests
</span></span><span style=display:flex><span>    Completed 90000 requests
</span></span><span style=display:flex><span>    Completed 100000 requests
</span></span><span style=display:flex><span>    Finished 100000 requests
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Server Software:        nginx/1.9.12
</span></span><span style=display:flex><span>    Server Hostname:        perf-target-1
</span></span><span style=display:flex><span>    Server Port:            8080
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Document Path:          /
</span></span><span style=display:flex><span>    Document Length:        612 bytes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Concurrency Level:      10
</span></span><span style=display:flex><span>    Time taken for tests:   15.776 seconds
</span></span><span style=display:flex><span>    Complete requests:      100000
</span></span><span style=display:flex><span>    Failed requests:        0
</span></span><span style=display:flex><span>    Total transferred:      84500000 bytes
</span></span><span style=display:flex><span>    HTML transferred:       61200000 bytes
</span></span><span style=display:flex><span>    Requests per second:    6338.89 [#/sec] (mean)
</span></span><span style=display:flex><span>    Time per request:       1.578 [ms] (mean)
</span></span><span style=display:flex><span>    Time per request:       0.158 [ms] (mean, across all concurrent requests)
</span></span><span style=display:flex><span>    Transfer rate:          5230.83 [Kbytes/sec] received
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Connection Times (ms)
</span></span><span style=display:flex><span>                  min  mean[+/-sd] median   max
</span></span><span style=display:flex><span>    Connect:        0    0   0.2      0       3
</span></span><span style=display:flex><span>    Processing:     0    1  64.3      0    5003
</span></span><span style=display:flex><span>    Waiting:        0    1  64.3      0    5003
</span></span><span style=display:flex><span>    Total:          0    2  64.3      1    5003
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Percentage of the requests served within a certain time (ms)
</span></span><span style=display:flex><span>      50%      1
</span></span><span style=display:flex><span>      66%      1
</span></span><span style=display:flex><span>      75%      1
</span></span><span style=display:flex><span>      80%      1
</span></span><span style=display:flex><span>      90%      1
</span></span><span style=display:flex><span>      95%      1
</span></span><span style=display:flex><span>      98%      1
</span></span><span style=display:flex><span>      99%      2
</span></span><span style=display:flex><span>     100%   5003 (longest request)
</span></span></code></pre></div><p>Here we see mean latency is 1.5ms, but some outliers have high latency. It would be easy to misread this report as healthy even though the backend service is unresponsive for fully half of the test run. If your target SLA is 1 second, then your service is out of SLA for more than half of the test run—but you might never suspect that from this report!</p><p>With slow_cooker’s incremental results, however, we can see that there’s a consistent throughput bottleneck that needs deeper investigation. Also, it becomes much more clear that the 99.9th percentile is consistently high; this is not just a few outliers, but a persistent and ongoing problem:</p><div class=highlight><pre tabindex=0 style=color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>$ ./slow_cooker_linux_amd64 -totalRequests 20000 -qps 50 -concurrency 10 http://perf-target-2:8080
</span></span><span style=display:flex><span>    # sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ...
</span></span><span style=display:flex><span>    #                      good/b/f t    good%    min [p50 p95 p99  p999]  max change
</span></span><span style=display:flex><span>    2016-12-07T19:05:37Z   2510/0/0 5000  50% 10s   0 [  0   0   2 4995 ] 4994 +
</span></span><span style=display:flex><span>    2016-12-07T19:05:47Z   2520/0/0 5000  50% 10s   0 [  0   0   1 4999 ] 4997 +
</span></span><span style=display:flex><span>    2016-12-07T19:05:57Z   2519/0/0 5000  50% 10s   0 [  0   0   1 5003 ] 5000 +
</span></span><span style=display:flex><span>    2016-12-07T19:06:07Z   2521/0/0 5000  50% 10s   0 [  0   0   1 4983 ] 4983 +
</span></span><span style=display:flex><span>    2016-12-07T19:06:17Z   2520/0/0 5000  50% 10s   0 [  0   0   1 4987 ] 4986
</span></span><span style=display:flex><span>    2016-12-07T19:06:27Z   2520/0/0 5000  50% 10s   0 [  0   0   1 4991 ] 4988
</span></span><span style=display:flex><span>    2016-12-07T19:06:37Z   2520/0/0 5000  50% 10s   0 [  0   0   1 4995 ] 4992
</span></span><span style=display:flex><span>    2016-12-07T19:06:47Z   2520/0/0 5000  50% 10s   0 [  0   0   2 4995 ] 4994
</span></span><span style=display:flex><span>    FROM    TO #REQUESTS
</span></span><span style=display:flex><span>       0     2 19996
</span></span><span style=display:flex><span>       2     8 74
</span></span><span style=display:flex><span>       8    32 0
</span></span><span style=display:flex><span>      32    64 0
</span></span><span style=display:flex><span>      64   128 0
</span></span><span style=display:flex><span>     128   256 0
</span></span><span style=display:flex><span>     256   512 0
</span></span><span style=display:flex><span>     512  1024 0
</span></span><span style=display:flex><span>    1024  4096 0
</span></span><span style=display:flex><span>    4096 16384 80
</span></span></code></pre></div><h2 id=percentile-based-latency-reporting>Percentile-based latency reporting</h2><p>As we see from the ApacheBench example above, some load testing tools will only output average and standard deviation. However, these metrics are <a href=http://www.brendangregg.com/FrequencyTrails/mean.html target=_blank rel=noopener>usually inappropriate for system latencies</a>. Latency does not follow a standard distribution, and often has very long tails. With slow_cooker, we discard mean and stddev entirely, showing instead the minimum, maximum, and a handful of higher-order percentiles (50th, 95th, 99th, and 99.9th). This approach has seen increased adoption in modern software systems, where a single request can result in dozens or even hundreds of queries to other systems. In these situations, metrics like the 95th and 99th percentiles represent the dominant latency for end users.</p><h2 id=conclusion>Conclusion</h2><p>Although writing a load generator is not ultimately particularly <em>difficult</em>, especially with modern, concurrent, network-oriented languages like Go, the details of reporting and measuring can make a significant difference in the utility of the tool.</p><p>Today, we use slow_cooker extensively to test Linkerd as well as other projects in the ecosystem (e.g. nginx). We currently run 24x7 tests against Linkerd in the context of complex multi-service software. slow_cooker has helped us not only keep buggy code from being deployed, but it has also <a href=https://github.com/linkerd/linkerd/issues/392 target=_blank rel=noopener>identified performance problems in existing code</a>. Usage of slow_cooker has become so pervasive at Buoyant that we refer to load testing a piece of software as “slow cooking” it.</p><p>You can get started using slow_cooker today by visiting the <a href=https://github.com/buoyantio/slow_cooker/releases target=_blank rel=noopener>Github releases page</a>. Download the tool and fire it at your favorite backend to start vetting it for performance issues. We hope you’ll find it as useful in your setup as we have in our tests of Linkerd.</p><h2 id=further-reading>Further reading</h2><ol><li><a href=http://perfdynamics.blogspot.com/2012/01/throughput-delay-curves.html target=_blank rel=noopener>Throughput-Delay Curves</a></li><li><a href=http://www.brendangregg.com/FrequencyTrails/mean.html target=_blank rel=noopener>Frequency Trails: What the Mean Really Means</a></li><li><a href=http://saladwithsteve.com/2008/06/simulating-byzantine-failure-with.html target=_blank rel=noopener>Simulating Byzantine Failure with SIGSTOP</a></li><li><a href=https://dzone.com/articles/everything-you-know-about-latency-is-wrong-brave-n target=_blank rel=noopener>Everything You Know About Latency Is Wrong</a></li><li><a href="https://www.youtube.com/watch?v=lJ8ydIuPFeU&amp;feature=youtu.be" target=_blank rel=noopener>How NOT to measure latency</a></li></ol></div></div></div></div></main><footer class=main-footer><div class=main-footer__top><div class="main-footer__container container"><div class=main-footer__info><p><img src=/logos/linkerd.png alt=Linkerd></p><p>Linkerd was originally created by <a href=https://buoyant.io/ target=_blank rel=noopener>Buoyant</a></p><p>View <a href=https://github.com/linkerd/linkerd/wiki/Linkerd-code-of-conduct target=_blank rel=noopener>Code of Conduct</a></p></div><div class=main-footer__links><div class=main-footer__community><h4>Community</h4><ul><li><a href=https://github.com/linkerd/linkerd2 target=_blank rel=noopener>GitHub</a></li><li><a href=https://slack.linkerd.io target=_blank rel=noopener>Slack</a></li><li><a href=https://linkerd.buoyant.io target=_blank rel=noopener>Linkerd Forum</a></li></ul></div><div class=main-footer__follow><h4>Follow</h4><ul><li><a href=https://www.linkedin.com/company/linkerd/ target=_blank rel=noopener>Linkedin</a></li><li><a href=https://www.youtube.com/buoyantio target=_blank rel=noopener>YouTube</a></li><li><a href=https://twitter.com/linkerd target=_blank rel=noopener>Twitter</a></li></ul></div></div></div></div><div class=main-footer__bottom><div class="main-footer__container container"><p><a href=https://github.com/linkerd/website/tree/main/linkerd.io/content target=_blank rel=noopener>Edit This Site</a></p><p>Copyright © 2024 Linkerd Authors. All rights reserved.</p></div></div></footer></body></html>